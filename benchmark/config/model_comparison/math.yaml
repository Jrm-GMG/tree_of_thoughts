# Model comparison for Math reasoning
extends: defaults.yaml

task: math
num_problems: 100

# Dataset configuration
dataset:
  random_selection: true

# Models to compare
models:
  - "microsoft/Phi-4-mini-reasoning"
  - "meta-llama/Llama-3.2-3B-Instruct"
  - "Qwen/Qwen3-4B"
strategies:
  - baseline_direct
  - baseline_cot
  - dfs
  - astar
  - bfs

output:
  summary: "benchmark/results/math_model_comparison.csv"
  detailed: "benchmark/results/math_model_metrics.json"
